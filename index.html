<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="choosing is more important">
<meta property="og:type" content="website">
<meta property="og:title" content="the world of healerson">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="the world of healerson">
<meta property="og:description" content="choosing is more important">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="healerson">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>the world of healerson</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">the world of healerson</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/22/11111/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="healerson">
      <meta itemprop="description" content="choosing is more important">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the world of healerson">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/22/11111/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-22 21:27:30" itemprop="dateCreated datePublished" datetime="2021-04-22T21:27:30+08:00">2021-04-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基于PaddlePaddle的李宏毅机器学习——迁移学习"><a href="#基于PaddlePaddle的李宏毅机器学习——迁移学习" class="headerlink" title="基于PaddlePaddle的李宏毅机器学习——迁移学习"></a>基于PaddlePaddle的李宏毅机器学习——迁移学习</h1><blockquote>
<p>大噶好，我是黄波波，一名入门不久自学AI的AI Trainer,宝可梦训练师（纯属业余）。希望能和大家共进步，错误之处恳请指出！<br><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/616597">百度AI Studio个人主页</a>, 我在AI Studio上获得白银等级，点亮2个徽章，来互关呀~</p>
</blockquote>
<blockquote>
<h3 id="本项目是在飞桨深度学习学院提供的李宏毅-机器学习特训营课程。"><a href="#本项目是在飞桨深度学习学院提供的李宏毅-机器学习特训营课程。" class="headerlink" title="本项目是在飞桨深度学习学院提供的李宏毅-机器学习特训营课程。"></a>本项目是在飞桨深度学习学院提供的<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/education/group/info/1978">李宏毅-机器学习</a>特训营课程。</h3></blockquote>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文共分为两大部分：第一部分介绍迁移学习的主要概念以及类型，第二部分是实现迁移学习布置的作业——领域对抗性训练(Domain Adversarial Training)并进行了三次不同epoch的训练。</p>
<h1 id="第一部分：迁移学习介绍"><a href="#第一部分：迁移学习介绍" class="headerlink" title="第一部分：迁移学习介绍"></a>第一部分：迁移学习介绍</h1><h2 id="1-迁移学习：Transfer-Learning"><a href="#1-迁移学习：Transfer-Learning" class="headerlink" title="1 迁移学习：Transfer Learning"></a>1 迁移学习：Transfer Learning</h2><h2 id="1-1-什么是迁移学习呢？"><a href="#1-1-什么是迁移学习呢？" class="headerlink" title="1.1 什么是迁移学习呢？"></a>1.1 什么是迁移学习呢？</h2><p>假设现在要做猫和狗的分类器，我们需要一样标签数据告诉机器哪些是猫，哪些是狗。<br>同时，假设现在有一些与猫和狗没有直接关系的数据，这里说是没有直接关系，并不是说是完全没有关系。就是说有一些关系，但又不是直接相关的。<br><img src="https://img-blog.csdnimg.cn/20210415122437342.png" alt="在这里插入图片描述"><br>假设现在有自然界真实存在的老虎和大象的图片，那老虎和大象对分辨猫和狗会有帮助吗。<br><img src="https://img-blog.csdnimg.cn/20210415122631945.png" alt="在这里插入图片描述"><br>或者说我们有一些卡通动画中的猫和狗图像，但不是真实存在的，有没有帮助呢。<br><img src="https://img-blog.csdnimg.cn/20210415122751953.png" alt="在这里插入图片描述"><br>迁移学习把任务A开发的模型作为初始点，重新使用在为任务B开发模型的过程中。迁移学习是通过从已学习的相关任务中转移知识来改进学习的新任务。</p>
<h2 id="1-2-为什么用迁移学习"><a href="#1-2-为什么用迁移学习" class="headerlink" title="1.2 为什么用迁移学习"></a>1.2 为什么用迁移学习</h2><p>这三个说的是，第一个是做闽南语(台湾腔)的语音识别，但是没有太多的训练数据，只有很多无直接关系的英文、普通话数据；第二是做医疗方面的图像识别，同样样本不多，但有很多其他真实动物的图像；第三个说的是在特定领域，这里是法律方面的文本分析，缺少数据，但是可以找到很多不相关的网页数据。</p>
<p>这时候迁移学习就会很有用，因为可能实际情况就是这样，我们无法收集太多想要的数据，但是存在很多不直接相关的其他数据。<br><img src="https://img-blog.csdnimg.cn/20210415123031818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>其实在现实生活中我们会做迁移学习（有点像类比的思想）。</p>
<p>这里用漫画家的生活对应到研究生的生活。漫画家要画漫画，研究生要跑实验等。<br><img src="https://img-blog.csdnimg.cn/20210415123211214.png" alt="在这里插入图片描述"></p>
<h2 id="1-3-迁移学习的概述"><a href="#1-3-迁移学习的概述" class="headerlink" title="1.3 迁移学习的概述"></a>1.3 迁移学习的概述</h2><p>我们主要把迁移学习分为四大类。<br>在迁移学习中，有一些arget data，就是和你的任务由直接关系的数据；<br>还有很多source data,是和你现在的任务没有直接关系的数据。</p>
<p>根据它们是否有标签，可以分成四类。<br><img src="https://img-blog.csdnimg.cn/2021041512335336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-3-1-第一类迁移学习"><a href="#1-3-1-第一类迁移学习" class="headerlink" title="1.3.1 第一类迁移学习"></a>1.3.1 第一类迁移学习</h3><p>我们先看下target data和source data都是有标签的情况。</p>
<p>这种情况下我们可以做什么事情呢，一件事情是模型的微调(Fine-tuning)，另一件事情是多任务学习(Multitask Learning)。</p>
<ul>
<li><h2 id="1-模型微调"><a href="#1-模型微调" class="headerlink" title="1) 模型微调"></a>1) 模型微调</h2>设你有一组大量的source data，和一组少量的target data。它们都是有标签的。<br><img src="https://img-blog.csdnimg.cn/20210415123842675.png#pic_center" alt="在这里插入图片描述"><br>你可能听过单样本学习(one-shot learning)：说现在的样本很少，只有几个或一个样本。</li>
</ul>
<p>在语音识别中，我们有大量的source data,我们有几万个人说的不同的句子，并且知道这些句子是什么。target data是某个具体的使用者他说的话，和说的话对应的文字。</p>
<p>因为每个人发音都是不一样的，你拿一大堆人语音的数据训练出来的模型，对某个特定的使用者，可能并不是一定好的。所以我们期望说，假设特定的使用者可以对我们的语音识别系统说5句话，我们知道这5句话对应的文字。</p>
<p>有了这些少量的target data后，就可以拿这些数据让某个特定使用者的语音识别做得更好。这让我想到了”Hey,siri”初次启用时需要说几句话。</p>
<p>这里面的问题是target data数据量很少，所以我们需要特殊的处理方法。一个比较常见的方法叫保守训练(conservative training)。由于篇幅有限这里不将展开，具体详见李宏毅机器学习课件。</p>
<p>接下来我们介绍下多任务学习(Multitask Learning)</p>
<ul>
<li><h2 id="2-多任务学习"><a href="#2-多任务学习" class="headerlink" title="2) 多任务学习"></a>2) 多任务学习</h2>我们现在有多个不同的任务，我们希望机器能同时学会做好这几个不同的任务。</li>
</ul>
<p>比如说你要训练某个人打篮球，同时要训练他唱、跳、Rap。<br><img src="https://img-blog.csdnimg.cn/20210416100235181.gif#pic_center" alt="在这里插入图片描述"></p>
<p>我们希望NN也能做到这件事情。</p>
<p>在这种神经网络的架构设计上可以是像上面这种。这里假设任务A和任务B可以共用同一组输入特征。就是这两个NN，它们前面几层是共用的，但是在某个隐藏层会产生两个分支，一条产生的是任务A的分支，另一条是任务B的。<br><img src="https://img-blog.csdnimg.cn/20210415124649256.png" alt="在这里插入图片描述"><br>那如果这两个任务的输入特征都不能共用呢，我们就可以采用上面的设计，在这两个NN中对不同的输入特征做一些转换，然后丢到共用的网络层中去，再从共用的层中分两个分支出来。<br><img src="https://img-blog.csdnimg.cn/20210415124708437.png" alt="在这里插入图片描述"><br>如果可以选择适当的不同的任务合在一起的话，是可以有帮助的。<br>什么样的任务可能有帮助呢，举例来说，现在在做语音识别的时候，我们不仅让机器学会某国语言的语音识别，我们让机器学会多国语言的。<br><img src="https://img-blog.csdnimg.cn/20210415124809586.png" alt="在这里插入图片描述"><br>此时，多任务学习就会有帮助。<br>这多国语言前面几层是共用的，因为不同的语音声音讯号是一样的(人类的语言都会有一些同样的特征，比如中文里面的嘿和英语里面的hey发音很像)。从这些共用的层出来后分成多个分支，分别做不同国家语言的语音识别。这整个NN可以同时一起训练，这时候学出来的效果比只用一种语言还要好。</p>
<p>这里是文献上的实验的例子，纵轴是错误率，横轴是中文语言识别训练的数据量。<br>从实验结果看到，如果仅让机器学中文的话，就是蓝色的线，它达到红线交点处的错误率需要的中文数据量会超过同时与欧洲语言一起学习的数据量。并且可以看到橙色的曲线是在蓝色曲线的下方，说明效果更加好。<br><img src="https://img-blog.csdnimg.cn/20210415125108449.png" alt="在这里插入图片描述"><br>还有另外一个任务学习方法叫渐进式网络(Progressive Neural Networks)，这里不将展开。</p>
<h3 id="1-3-2-第二类迁移学习"><a href="#1-3-2-第二类迁移学习" class="headerlink" title="1.3.2 第二类迁移学习"></a>1.3.2 第二类迁移学习</h3><p>上面介绍的都是source data和target data有标签的情况，那如果只是source data有标签，target data无标签呢。这种类型也有两种情况，第一种是领域对抗性训练(Domain Adversarial Training)，第二种是零次学习(Zero-shot Learning)。第二种情况是第二部分代码实现的内容。</p>
<ul>
<li><h2 id="1-领域对抗性训练-Domain-Adversarial-Training"><a href="#1-领域对抗性训练-Domain-Adversarial-Training" class="headerlink" title="1)领域对抗性训练(Domain Adversarial Training)"></a>1)领域对抗性训练(Domain Adversarial Training)</h2>这种情况的前提是他们有相同的任务，在概念上你可以把有标签的source data当成训练数据，把无标签的target data当成测试数据，但是这样的效果肯定是很差的，因为它们的分布不同。<br><img src="https://img-blog.csdnimg.cn/20210415140556375.png" alt="在这里插入图片描述"><br>假设今天要做手写数字识别，你有有标签的MNIST的数据，但是你要识别的对象是无标签的来自MNIST-M的数据，在MNIST-M中的数字甚至是彩色的，它的数据样本分布和原来的MNIST分布不一样。<br><img src="https://img-blog.csdnimg.cn/20210415141052765.png" alt="在这里插入图片描述"><br>所以需要特别的处理。Domain-adversarial training就是干这件事的。Domain-adversarial training可以看成GAN的一种。它想要把source data和target data转换到同样的领域上，让它们有同样的分布。<br><img src="https://img-blog.csdnimg.cn/20210415141833915.png" alt="在这里插入图片描述"><br>如果我们没有对数据做任何处理，单纯的拿source data来训练一个分类器，它输入是一个图像，输出是该图形的类别。那今天得到的特征分布可能是下面这样子。<br><img src="https://img-blog.csdnimg.cn/20210415141414902.png" alt="在这里插入图片描述"><br>MNIST的数据它是蓝色的点，确实可以看到它们分成一群一群的，把几群数据的点拿出来看的话，得到的结果可能是左边的样子，能区分出4,0和1。 但是把和MNIST分布不同的MNIST-M手写数字的图片丢到这个分类器中去，这些不一样的图片，它们的特征分布可能像红点一样。可以看到，红点和蓝点根本没有交集。<br>如果今天这个NN无法用同样的特征表示这两种数据，那么就会无法得到好的分类结果。</li>
</ul>
<p>怎么办呢</p>
<p>我们希望在一个NN中，前面几个网络层做的事是特征抽取，如图1所示，也就是说，希望这个特征抽取器能把不同领域的source data和target data都转成同样的特征。<img src="https://img-blog.csdnimg.cn/img_convert/a0fb7213eb449144f30d5dc5639b2885.png"></p>
<blockquote>
<p>图1 Feature Extractor：特征提取器</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20210415142100358.png" alt="在这里插入图片描述"><br>也就是我们希望说，红点和蓝点的分布不是上面这样，而是像下面混合在一起。<br><img src="https://img-blog.csdnimg.cn/20210415142139276.png" alt="在这里插入图片描述"><br>那怎么让我们这个特征抽取器做到这件事情呢。</p>
<p>这里需要引入一个领域的分类器(domain classifier)，如图2所示，就像我们做GAN的时候引入的鉴别器。它也是一个神经网络。<br><img src="https://img-blog.csdnimg.cn/img_convert/a93819091f5dd5f245495f4e342caba4.png"></p>
<blockquote>
<p>图2  Domain Classifier领域的分类器</p>
</blockquote>
<p>Domain-adversarial training可以看成GAN的一种。它想要把source data和target data转换到同样的领域上，让它们有同样的分布。</p>
<p>这个领域分类器的作用是，要侦测出现在特征抽取器输出的特征是属于哪个领域的(来自哪个分布的)。现在特征抽取器要做的事情是尽量骗过这个领域分类器，而后者是尽量防止被骗。</p>
<p>特征抽取器要做的是去除source 领域和target 领域不一样的地方，让提取出来的特征分布是很接近的，可以骗过领域分类器。</p>
<p>但是如果只有这两个神经网络是不够的。因为绿色的特征抽取器可以轻易的骗过红色的分类器，只要它不管输入是什么，只把所有的输出都变成0就可以了。</p>
<p>所以需要引入另外一个东西叫标签预测器(Label predictor)的东西。<br><img src="https://img-blog.csdnimg.cn/img_convert/69eeea1f5f0fb8b61a8b05200982a564.png"></p>
<blockquote>
<p>图3 Label predictor：标签预测器</p>
</blockquote>
<p>现在特征抽取器不仅要骗过分类器，还要让预测器尽量有准确的预测结果。这是一个很大的神经网络，但是这三个不同的部分有不同的目标。</p>
<p>预测器想要正确的分类输入的图片，分类器想要正确分别输入是来自哪个分布。它们都只能看到特征抽取器抽取后的特征。</p>
<p>抽取器一方面希望可以促使预测器做的好，另一方面要防止分类器做的好。</p>
<p>那么要怎么做呢？</p>
<p>一样用梯度下降来训练，红色的分类器部分要调整参数，去让分辨领域的结果越正确越好；蓝色的预测器需要调参数，让标签的预测正确率越高越好；如图4所示梯度反向传播过程。</p>
<p>这两者不一样的地方在于，当分类器要求绿色的抽取器去调整参数以满足以及的目标时，绿色的抽取器会尽量满足它的要求；还当红色的神经网络要求绿色的神经网络调整参数的时候，红色的网络会故意乘以− 1 -1−1，以防止分类器做的好。</p>
<p>最后红色的神经网路会无法做好分类，但是它必须要努力挣扎，它需要从绿色的NN给的不好的特征里面尽量去区分它们的领域。这样才能迫使绿色的NN产生红色的NN无法分辨的特征。难点就在于让红色的NN努力挣扎而不是很快放弃。<br><img src="https://img-blog.csdnimg.cn/20210415142358336.png" alt="在这里插入图片描述"></p>
<blockquote>
<p>图4 Domain Adversarial Training梯度反向传播过程</p>
</blockquote>
<ul>
<li><h2 id="2-零次学习（Zero-shot-Learning）"><a href="#2-零次学习（Zero-shot-Learning）" class="headerlink" title="2)零次学习（Zero-shot Learning）"></a>2)零次学习（Zero-shot Learning）</h2>零次学习(Zero-shot Learning)说的是source data和target data它们的任务都不相同。<br><img src="https://img-blog.csdnimg.cn/20210415142857386.png" alt="在这里插入图片描述"><br>比如source data可能是要做猫和狗的分类；但是target data要做的是做草泥马和羊的分类。<br><img src="https://img-blog.csdnimg.cn/20210415142909487.png" alt="在这里插入图片描述"><br>target data中需要正确找出草泥马，但是source data中都没出现过草泥马，那要怎么做这件事情呢<br>我们先看下语音识别里面是怎么做的，语音识别一直都有训练数据(source data)和测试数据(target data)是不同任务的问题。 很有可能在测试数据中出现的词汇，在训练数据中从来没有出现过。语音识别在处理这个问题的时候，做法是找出比词汇更小的单位。通常语音识别都是拿音位(phoneme，可以理解为音标)做为单位。</li>
</ul>
<p>如果把词汇都转成音位，在识别的时候只去识别音位，然后再把音位转换为词汇的话就可以解决训练数据和测试数据不一样的问题。</p>
<p>其实在图像上的处理方法也很类似，这里不展开。</p>
<h3 id="1-3-3-第三类迁移学习"><a href="#1-3-3-第三类迁移学习" class="headerlink" title="1.3.3 第三类迁移学习"></a>1.3.3 第三类迁移学习</h3><ul>
<li><h2 id="自我学习"><a href="#自我学习" class="headerlink" title="自我学习"></a>自我学习</h2>自我学习(Self-taught learning)其实和半监督学习很像，都是有少量的有标签数据，和非常多的无标签数据。但是与半监督学习有个很大的不同是，有标签数据可能和无标签数据是没有关系的。<h3 id="1-3-4-第四类迁移学习"><a href="#1-3-4-第四类迁移学习" class="headerlink" title="1.3.4 第四类迁移学习"></a>1.3.4 第四类迁移学习</h3></li>
<li><h2 id="自学成簇"><a href="#自学成簇" class="headerlink" title="自学成簇"></a>自学成簇</h2>如果target data和source data都是无标签的话，可以用Self-taught Clustering来做。<br>可以用无标签的source data，可以学出一个较好的特征表示，再用这个较好的特征表示用在聚类上，就可以得到较好的结果。<h1 id="第二部分：领域对抗性训练-Domain-Adversarial-Training-代码实现"><a href="#第二部分：领域对抗性训练-Domain-Adversarial-Training-代码实现" class="headerlink" title="第二部分：领域对抗性训练(Domain Adversarial Training)代码实现"></a>第二部分：领域对抗性训练(Domain Adversarial Training)代码实现</h1><h2 id="2-1-项目描述"><a href="#2-1-项目描述" class="headerlink" title="2.1 项目描述"></a>2.1 项目描述</h2>本作业的任务是迁移学习中的领域对抗性训练(Domain Adversarial Training)。  <blockquote>
<p>也就是左下角的那一块。</p>
</blockquote>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/c45384f70bd12de95861b9fdfcc724b0.png"><br>Domain Adaptation是让模型可以在训练时只需要 A dataset label，不需要 B dataset label 的情况下提高 B dataset 的准确率。 （A dataset &amp; task 接近 B dataset &amp; task）也就是给定真实图片 &amp; 标签以及大量的手绘图片，请设计一种方法使得模型可以预测出手绘图片的标签是什么。<br><img src="https://img-blog.csdnimg.cn/img_convert/8c577e960c5a01067c1a90109ef61dd0.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/8f4a8c8d55946784b2c7bb986017130c.png"></p>
<h2 id="2-2-数据集介绍"><a href="#2-2-数据集介绍" class="headerlink" title="2.2 数据集介绍"></a>2.2 数据集介绍</h2><p>这次的任务是源数据: 真实照片，目标数据: 手画涂鸦。<br>我们必须让model看过真实照片以及标签，尝试去预测手画涂鸦的标签为何。<br>资料位于’data/data58171/real_or_drawing.zip’</p>
<ul>
<li>Training : 5000 张真实图片 + label, 32 x 32 RGB</li>
<li>Testing : 100000 张手绘图片，28 x 28 Gray Scale</li>
<li>Label: 总共需要预测 10 个 class。</li>
<li>资料下载下来是以 0 ~ 9 作为label<br>特别注意一点: <strong>这次的源数据和目标数据的图片都是平衡的，你们可以使用这个资料做其他事情。</strong><h3 id="项目要求"><a href="#项目要求" class="headerlink" title="项目要求"></a>项目要求</h3></li>
<li>禁止手动标记label或在网上寻找label</li>
<li>禁止使用pre-trained model<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1769443">项目传送门</a><h1 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3 代码实现"></a>3 代码实现</h1><h2 id="3-1-数据集查看"><a href="#3-1-数据集查看" class="headerlink" title="3.1 数据集查看"></a>3.1 数据集查看</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相关库</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
  /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/<strong>init</strong>.py:107: DeprecationWarning: Using or importing the ABCs from ‘collections’ instead of from ‘collections.abc’ is deprecated, and in 3.8 it will stop working<pre><code>from collections import MutableMapping
</code></pre>
  /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from ‘collections’ instead of from ‘collections.abc’ is deprecated, and in 3.8 it will stop working<pre><code>from collections import Iterable, Mapping
</code></pre>
  /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from ‘collections’ instead of from ‘collections.abc’ is deprecated, and in 3.8 it will stop working<pre><code>from collections import Sized
</code></pre>
  2021-04-14 17:30:09,287 - INFO - font search path [‘/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf’, ‘/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm’, ‘/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts’]<br>  2021-04-14 17:30:09,624 - INFO - generated new fontManager<br>展示一下训练集<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">no_axis_show</span>(<span class="params">img, title=<span class="string">&#x27;&#x27;</span>, cmap=<span class="literal">None</span></span>):</span></span><br><span class="line">  <span class="comment"># imshow, 縮放模式為nearest。</span></span><br><span class="line">  fig = plt.imshow(img, interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap=cmap)</span><br><span class="line">  <span class="comment"># 不要显示axis</span></span><br><span class="line">  fig.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">  fig.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">  plt.title(title)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#标签映射</span></span><br><span class="line">titles = [<span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;bed&#x27;</span>, <span class="string">&#x27;clock&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;television&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;dolphin&#x27;</span>, <span class="string">&#x27;spider&#x27;</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">  plt.subplot(<span class="number">1</span>, <span class="number">10</span>, i+<span class="number">1</span>)</span><br><span class="line">  fig = no_axis_show(plt.imread(<span class="string">f&#x27;work/real_or_drawing/train_data/<span class="subst">&#123;i&#125;</span>/<span class="subst">&#123;<span class="number">500</span>*i&#125;</span>.bmp&#x27;</span>), title=titles[i])</span><br><span class="line"><span class="comment">#  work/real_or_drawing/train_data/1/566.bmp</span></span><br></pre></td></tr></table></figure>
<img src="https://img-blog.csdnimg.cn/20210415143820728.png#pic_center" alt="在这里插入图片描述"><br>展示一下测试集<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">10</span>, i + <span class="number">1</span>)</span><br><span class="line">    fig = no_axis_show(plt.imread(<span class="string">f&#x27;work/real_or_drawing/test_data/0/0000<span class="subst">&#123;i&#125;</span>.bmp&#x27;</span>), title=<span class="string">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>
<img src="https://img-blog.csdnimg.cn/2021041514385115.png#pic_center" alt="在这里插入图片描述"><h2 id="3-2-Special-Domain-Knowledge"><a href="#3-2-Special-Domain-Knowledge" class="headerlink" title="3.2 Special Domain Knowledge"></a>3.2 Special Domain Knowledge</h2><h3 id="预处理source-data"><a href="#预处理source-data" class="headerlink" title="预处理source data"></a>预处理source data</h3>因为大家涂鸦的时候通常只会画轮廓，我们可以根据这点将source data做点边缘侦测处理，让source data更像target data一点。<br>Canny Edge Detection<br>算法这边不赘述，只教大家怎么用。若有兴趣欢迎参考wiki或这里。<br>cv2.Canny使用非常方便，只需要两个参数: low_threshold, high_threshold。<blockquote>
<p>cv2.Canny(image, low_threshold, high_threshold)</p>
</blockquote>
</li>
</ul>
<p>简单来说就是当边缘值超过high_threshold，我们就确定它是edge。如果只有超过low_threshold，那就先判断一下再决定是不是edge。</p>
<p>以下我们直接拿source data做做看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">titles = [<span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;bed&#x27;</span>, <span class="string">&#x27;clock&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;television&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;dolphin&#x27;</span>, <span class="string">&#x27;spider&#x27;</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line"></span><br><span class="line">original_img = plt.imread(<span class="string">f&#x27;work/real_or_drawing/train_data/0/464.bmp&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">no_axis_show(original_img, title=<span class="string">&#x27;original&#x27;</span>)</span><br><span class="line"></span><br><span class="line">gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">no_axis_show(gray_img, title=<span class="string">&#x27;gray scale&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">canny_50100 = cv2.Canny(gray_img, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">no_axis_show(canny_50100, title=<span class="string">&#x27;Canny(50, 100)&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">canny_150200 = cv2.Canny(gray_img, <span class="number">150</span>, <span class="number">200</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">no_axis_show(canny_150200, title=<span class="string">&#x27;Canny(150, 200)&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">canny_250300 = cv2.Canny(gray_img, <span class="number">250</span>, <span class="number">300</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">no_axis_show(canny_250300, title=<span class="string">&#x27;Canny(250, 300)&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210415144213282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="3-4-Data-Process"><a href="#3-4-Data-Process" class="headerlink" title="3.4 Data Process"></a>3.4 Data Process</h2><p>在这里因为train_data的格式已经标注好每种图片，可以直接使用<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/datasets/folder/DatasetFolder_cn.html">paddle.vision.datasets.DatasetFolder</a>。所以只要使用这个API便可以做出一个datasets。在这里要是说明的是用DataFolder读取的时候有两个存放位置，这两个位置分别存放图片和标签。</p>
<p>此外还有数据预处理部分见下面代码：</p>
<h3 id="3-4-1-数据预处理"><a href="#3-4-1-数据预处理" class="headerlink" title="3.4.1 数据预处理"></a>3.4.1 数据预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.vision.transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> paddle.vision.datasets <span class="keyword">import</span> DatasetFolder,ImageFolder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">source_transform</span>(<span class="params">imge</span>):</span></span><br><span class="line">    <span class="comment"># 转灰色: Canny 不吃 RGB。</span></span><br><span class="line">    img = T.to_grayscale(imge)</span><br><span class="line">    <span class="comment"># cv2 不吃 skimage.Image，因此转成np.array后再做cv2.Canny</span></span><br><span class="line">    img = cv2.Canny(np.array(img), <span class="number">170</span>, <span class="number">300</span>)</span><br><span class="line">    <span class="comment"># 重新np.array 转回 skimage.Image</span></span><br><span class="line">    img = Image.fromarray(np.array(img))</span><br><span class="line">    <span class="comment"># 随机水平翻转 (Augmentation)</span></span><br><span class="line">    RHF= T.RandomHorizontalFlip(<span class="number">0.5</span>)</span><br><span class="line">    img = RHF(img)</span><br><span class="line">    <span class="comment"># 旋转15度内 (Augmentation)，旋转后空的地方补0</span></span><br><span class="line">    RR = T.RandomRotation(<span class="number">15</span>, fill=(<span class="number">0</span>,))</span><br><span class="line">    img = RR(img)</span><br><span class="line">    <span class="comment"># 最后Tensor供model使用。</span></span><br><span class="line">    tensor = T.ToTensor()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tensor(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集预处理</span></span><br><span class="line">target_transform = T.Compose([</span><br><span class="line">    <span class="comment"># 转灰阶:</span></span><br><span class="line">   T.Grayscale(),</span><br><span class="line">    <span class="comment"># 缩放: 因为source data是32x32，我们把target data的28x28放大成32x32。</span></span><br><span class="line">    T.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">    <span class="comment"># 随机水平翻转(Augmentation)</span></span><br><span class="line">    T.RandomHorizontalFlip(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 旋转15度内 (Augmentation)，旋转后空的地方补0</span></span><br><span class="line">    T.RandomRotation(<span class="number">15</span>, fill=(<span class="number">0</span>,)),</span><br><span class="line">    <span class="comment"># 最后Tensor供model使用。</span></span><br><span class="line">    T.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment">#下面调用一下数据预处理函数</span></span><br><span class="line">original_img = Image.<span class="built_in">open</span>(<span class="string">f&#x27;work/real_or_drawing/train_data/0/464.bmp&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原来的照片形状：&#x27;</span>,np.array(original_img).shape)</span><br><span class="line">process = source_transform(original_img)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预处理后的照片形状：&#x27;</span>,process .shape)</span><br><span class="line"><span class="built_in">print</span>(process)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">no_axis_show(process .numpy().squeeze(), title=<span class="string">&#x27;process image&#x27;</span>,cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">no_axis_show(original_img, title=<span class="string">&#x27;origimal image&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>原来的照片形状： (32, 32, 3)
预处理后的照片形状： [1, 32, 32]
Tensor(shape=[1, 32, 32], dtype=float32, place=CUDAPlace(0), stop_gradient=True,
       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]])
</code></pre>
<p><img src="https://img-blog.csdnimg.cn/20210415144533297.png" alt="在这里插入图片描述"></p>
<h3 id="3-4-2-数据加载器定义"><a href="#3-4-2-数据加载器定义" class="headerlink" title="3.4.2 数据加载器定义"></a>3.4.2 数据加载器定义</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line">source_dataset = DatasetFolder(<span class="string">&#x27;work/real_or_drawing/train_data&#x27;</span>, transform=source_transform) <span class="comment"># DatasetFolder 用于读取训练集，读取的时候图片和标签</span></span><br><span class="line">target_dataset = DatasetFolder(<span class="string">&#x27;work/real_or_drawing/test_data&#x27;</span>, transform=target_transform) <span class="comment"># ImageFolder 用于读取测试集，读取的时候只有图片</span></span><br><span class="line"><span class="comment"># 数据加载器定义</span></span><br><span class="line">source_dataloader = paddle.io.DataLoader(source_dataset, batch_size=<span class="number">50</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">target_dataloader = paddle.io.DataLoader(target_dataset, batch_size=<span class="number">50</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_dataloader = paddle.io.DataLoader(target_dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># 展示生成并经过预处理的的source_dataset和source_loader</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=============source_dataset=============&#x27;</span>)</span><br><span class="line"><span class="comment">#由于使用了DatasetFolder，训练集这里有图片和标签两个参数image,label</span></span><br><span class="line"><span class="keyword">for</span> image, label <span class="keyword">in</span> source_dataset:      </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image shape: &#123;&#125;, label: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(image.shape,label))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;训练集数量:&#x27;</span>,<span class="built_in">len</span>(source_dataset))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;图片：&#x27;</span>,image)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;标签：&#x27;</span>,label)</span><br><span class="line">    plt.imshow(image.numpy().squeeze(),cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<pre><code>=============source_dataset=============
image shape: [1, 32, 32], label: 0
训练集数量: 5000
图片： Tensor(shape=[1, 32, 32], dtype=float32, place=CUDAPlace(0), stop_gradient=True,
       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]])
标签： 0
</code></pre>
<p><img src="https://img-blog.csdnimg.cn/20210415144635963.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#source_loader的信息    </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=============source_dataloader=============&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> batch_id, (data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(source_dataloader):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;一个batch的图片：&#x27;</span>,data.shape)    <span class="comment"># 索引[0]存放图片</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;一个batch的标签个数：&#x27;</span>,label.shape)   <span class="comment">#索引[1]存放标签</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;图片：&#x27;</span>,data[<span class="number">0</span>].shape) </span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="comment"># no_axis_show(x_data.numpy().squeeze(),title=&#x27;process image&#x27;, cmap=&#x27;gray&#x27;)</span></span><br></pre></td></tr></table></figure>
<pre><code>=============source_dataloader=============
一个batch的图片： [50, 1, 32, 32]
一个batch的标签个数： [50]
图片： [1, 32, 32]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示生成并经过预处理的target_dataset和target_dataloader</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=============target_dataset=============&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> image_,_ <span class="keyword">in</span> target_dataset:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;image shape: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(image_.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;测试集数量:&#x27;</span>,<span class="built_in">len</span>(target_dataset))</span><br><span class="line">    plt.imshow(image_.numpy().squeeze(),cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;图片：&#x27;</span>,image_)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<pre><code>=============target_dataset=============
image shape: [1, 32, 32]
测试集数量: 100000
图片： Tensor(shape=[1, 32, 32], dtype=float32, place=CUDAPlace(0), stop_gradient=True,
       [[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]])
</code></pre>
<p><img src="https://img-blog.csdnimg.cn/20210415144820434.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#target_dataloader的信息    </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=============target_dataloader=============&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> batch_id, (data_1,label_1) <span class="keyword">in</span> <span class="built_in">enumerate</span>(target_dataloader):</span><br><span class="line">    <span class="comment"># print(&#x27;一个batch的图片：&#x27;,data[0].shape)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;一个batch的图片：&#x27;</span>,data_1.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;一张图片的形状：&#x27;</span>,data_1[<span class="number">0</span>].shape) </span><br><span class="line">    <span class="built_in">print</span>(label_1)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<pre><code>=============target_dataloader=============
一个batch的图片： [50, 1, 32, 32]
一张图片的形状： [1, 32, 32]
Tensor(shape=[50], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
</code></pre>
<h2 id="3-5-搭建三个模型"><a href="#3-5-搭建三个模型" class="headerlink" title="3.5 搭建三个模型"></a>3.5 搭建三个模型</h2><p>这里的原理参考本文的1.3.2 第二类迁移学习的领域对抗性训练(Domain Adversarial Training)。</p>
<ul>
<li>Feature Extractor: 典型的VGG-like叠法。</li>
<li>Label Predictor ：MLP到尾</li>
<li>Domain Classifier: MLP到尾。</li>
</ul>
<p>特征抽取器不仅要骗过分类器，还要让预测器尽量有准确的预测结果。这是一个很大的神经网络，但是这三个不同的部分有不同的目标。</p>
<p>预测器想要正确的分类输入的图片，分类器想要正确分别输入是来自哪个分布。它们都只能看到特征抽取器抽取后的特征</p>
<p>抽取器一方面希望可以促使预测器做的好，另一方面要防止分类器做的好。</p>
<p>那么要怎么做呢？详见下面的模型训练部分。<br><img src="https://img-blog.csdnimg.cn/img_convert/69eeea1f5f0fb8b61a8b05200982a564.png"></p>
<h3 id="3-5-1-搭建模型"><a href="#3-5-1-搭建模型" class="headerlink" title="3.5.1 搭建模型"></a>3.5.1 搭建模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureExtractor</span>(<span class="params">nn.Layer</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    从图片中抽取特征</span></span><br><span class="line"><span class="string">    input [batch_size ,1,32,32]</span></span><br><span class="line"><span class="string">    output [batch_size ,512]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FeatureExtractor, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(                               </span><br><span class="line">            nn.Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>,  stride=<span class="number">1</span>),  <span class="comment"># [batch_size ,64,32,32] (32-3+2*1)/1 + 1</span></span><br><span class="line">            nn.BatchNorm2D(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(kernel_size=<span class="number">2</span>),  <span class="comment"># [batch_size ,64,16,16]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2D(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [batch_size ,128,16,16]</span></span><br><span class="line">            nn.BatchNorm2D(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(<span class="number">2</span>),  <span class="comment"># [batch_size ,128,8,8]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2D(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [batch_size ,256,8,8]</span></span><br><span class="line">            nn.BatchNorm2D(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(<span class="number">2</span>),  <span class="comment"># [batch_size ,256,4,4]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2D(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [batch_size ,256,4,4]</span></span><br><span class="line">            nn.BatchNorm2D(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(<span class="number">2</span>),  <span class="comment"># [batch_size ,256,2,2]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2D(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [batch_size ,512,2,2]</span></span><br><span class="line">            nn.BatchNorm2D(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(<span class="number">2</span>),  <span class="comment"># [batch_size ,512,1,1]</span></span><br><span class="line">            nn.Flatten()      <span class="comment"># [batch_size ,512]</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x) <span class="comment"># [batch_size ,256]</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelPredictor</span>(<span class="params">nn.Layer</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    预测图像是什么动物</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LabelPredictor, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>,<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, h</span>):</span></span><br><span class="line">        c = self.layer(h)</span><br><span class="line">        <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DomainClassifier</span>(<span class="params">nn.Layer</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;预测时手绘还是真实图片&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DomainClassifier, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1D(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1D(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1D(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1D(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, h</span>):</span></span><br><span class="line">        y = self.layer(h)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<h3 id="3-5-2-模型配置"><a href="#3-5-2-模型配置" class="headerlink" title="3.5.2 模型配置"></a>3.5.2 模型配置</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.optimizer <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment"># 模型实例化</span></span><br><span class="line">feature_extractor = FeatureExtractor()</span><br><span class="line">label_predictor = LabelPredictor()</span><br><span class="line">domain_classifier = DomainClassifier()</span><br><span class="line">class_criterion = nn.CrossEntropyLoss()</span><br><span class="line">domain_criterion = nn.BCEWithLogitsLoss()</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer_F = optim.Adam(learning_rate=<span class="number">0.0001</span>, parameters=feature_extractor.parameters())</span><br><span class="line">optimizer_C = optim.Adam(learning_rate=<span class="number">0.0001</span>, parameters=label_predictor.parameters())</span><br><span class="line">optimizer_D = optim.Adam(learning_rate=<span class="number">0.0001</span>, parameters=domain_classifier.parameters())</span><br></pre></td></tr></table></figure>
<h3 id="3-5-3-开始训练"><a href="#3-5-3-开始训练" class="headerlink" title="3.5.3 开始训练"></a>3.5.3 开始训练</h3><p>用梯度下降来训练，红色的分类器部分要调整参数，去让分辨领域的结果越正确越好；蓝色的预测器需要调参数，让标签的预测正确率越高越好；</p>
<p>这两者不一样的地方在于，当分类器要求绿色的抽取器去调整参数以满足以及的目标时，绿色的抽取器会尽量满足它的要求；还当红色的神经网络要求绿色的神经网络调整参数的时候，红色的网络会故意乘以-1，以防止分类器做的好。</p>
<p>最后红色的神经网路会无法做好分类，但是它必须要努力挣扎，它需要从绿色的NN给的不好的特征里面尽量去区分它们的领域。这样才能迫使绿色的NN产生红色的NN无法分辨的特征。难点就在于让红色的NN努力挣扎而不是很快放弃。<br><img src="https://img-blog.csdnimg.cn/img_convert/370c88f7f57d4b7b564a36cab7aaba3b.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义训练函数</span></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">source_dataloader, target_dataloader, lamb</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      Args:</span></span><br><span class="line"><span class="string">        source_dataloader: source data的dataloader</span></span><br><span class="line"><span class="string">        target_dataloader: target data的dataloader</span></span><br><span class="line"><span class="string">        lamb: 调控adversarial的loss系数。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    running_D_loss, running_F_loss = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">    total_hit, total_num = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, ((source_data, source_label), (target_data,_)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(source_dataloader, target_dataloader)):</span><br><span class="line">        mixed_data = paddle.concat([source_data, target_data], axis=<span class="number">0</span>)</span><br><span class="line">        domain_label = paddle.zeros([source_data.shape[<span class="number">0</span>] + target_data.shape[<span class="number">0</span>], <span class="number">1</span>]).cuda()</span><br><span class="line">        <span class="comment"># 设定source data的label为1</span></span><br><span class="line">        domain_label[:source_data.shape[<span class="number">0</span>]] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1 : 训练Domain Classifier</span></span><br><span class="line">        feature = feature_extractor(mixed_data)</span><br><span class="line">        <span class="comment"># 因为我们在Step 1不需要训练Feature Extractor，所以把feature detach</span></span><br><span class="line">        <span class="comment">#这样可以把特征抽取过程的函数从当前计算图分离，避免loss backprop传递过去。</span></span><br><span class="line">        domain_logits = domain_classifier(feature.detach())</span><br><span class="line">        loss = domain_criterion(domain_logits, domain_label)</span><br><span class="line">        running_D_loss += loss.numpy().tolist()[<span class="number">0</span>]</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer_D.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2 : 训练Feature Extractor和Domain Classifier</span></span><br><span class="line">        class_logits = label_predictor(feature[:source_data.shape[<span class="number">0</span>]])</span><br><span class="line">        domain_logits = domain_classifier(feature)</span><br><span class="line">        <span class="comment"># loss为原本的class CE - lamb * domain BCE，相減的原因是我们希望特征能够使得domain_classifier分不出来输入的图片属于哪个领域</span></span><br><span class="line">        loss = class_criterion(class_logits, source_label) - lamb * domain_criterion(domain_logits, domain_label)</span><br><span class="line">        running_F_loss += loss.numpy().tolist()[<span class="number">0</span>]</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer_F.step()</span><br><span class="line">        optimizer_C.step()</span><br><span class="line">        <span class="comment">#训练了一轮，清空所有梯度信息</span></span><br><span class="line">        optimizer_D.clear_grad()</span><br><span class="line">        optimizer_F.clear_grad()</span><br><span class="line">        optimizer_C.clear_grad()</span><br><span class="line">        <span class="comment"># return class_logits,source_label  #测试</span></span><br><span class="line">        bool_eq = paddle.argmax(class_logits, axis=<span class="number">1</span>) == source_label.squeeze()</span><br><span class="line">        total_hit += np.<span class="built_in">sum</span>(bool_eq.numpy()!=<span class="number">0</span>)</span><br><span class="line">        total_num += source_data.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(i, end=<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> running_D_loss / (i+<span class="number">1</span>), running_F_loss / (i+<span class="number">1</span>), total_hit / total_num</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练125 epochs</span></span><br><span class="line">train_D_loss_history,train_F_loss_history,train_acc_history = [], [], []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">125</span>):</span><br><span class="line">    train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader, lamb=<span class="number">0.1</span>)</span><br><span class="line">    train_D_loss_history.append(train_D_loss)</span><br><span class="line">    train_F_loss_history.append(train_F_loss)</span><br><span class="line">    train_acc_history.append(train_acc)  </span><br><span class="line">    epoch = epoch + <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        paddle.save(feature_extractor.state_dict(), <span class="string">&quot;ckp/&#123;&#125;ckp_feature_extractor.pdparams&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(epoch)))</span><br><span class="line">        paddle.save(label_predictor.state_dict(), <span class="string">&quot;ckp/&#123;&#125;ckp_label_predictor.pdparams&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(epoch)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch &#123;:&gt;3d&#125;: train D loss: &#123;:6.4f&#125;, train F loss: &#123;:6.4f&#125;, acc &#123;:6.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_D_loss, train_F_loss, train_acc))                                                                            </span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance.
  &quot;When training, we now always track global mean and variance.&quot;)
5
epoch   1: train D loss: 0.0202, train F loss: 0.0416, acc 0.9844
epoch   2: train D loss: 0.0291, train F loss: 0.0400, acc 0.9824
epoch   3: train D loss: 0.0308, train F loss: 0.0378, acc 0.9872
epoch   4: train D loss: 0.0351, train F loss: 0.0576, acc 0.9792
epoch   5: train D loss: 0.0348, train F loss: 0.0456, acc 0.9830
epoch   6: train D loss: 0.0395, train F loss: 0.0360, acc 0.9860
epoch   7: train D loss: 0.0353, train F loss: 0.0508, acc 0.9822
epoch   8: train D loss: 0.0390, train F loss: 0.0348, acc 0.9874
epoch   9: train D loss: 0.0413, train F loss: 0.0503, acc 0.9808
epoch  10: train D loss: 0.0440, train F loss: 0.0480, acc 0.9796
epoch  11: train D loss: 0.0413, train F loss: 0.0428, acc 0.9834
epoch  12: train D loss: 0.0422, train F loss: 0.0402, acc 0.9842
epoch  13: train D loss: 0.0512, train F loss: 0.0506, acc 0.9782
epoch  14: train D loss: 0.0519, train F loss: 0.0549, acc 0.9814
epoch  15: train D loss: 0.0446, train F loss: 0.0309, acc 0.9878
epoch  16: train D loss: 0.0485, train F loss: 0.0395, acc 0.9858
epoch  17: train D loss: 0.0531, train F loss: 0.0445, acc 0.9826
epoch  18: train D loss: 0.0507, train F loss: 0.0370, acc 0.9864
epoch  19: train D loss: 0.0525, train F loss: 0.0516, acc 0.9812
epoch  20: train D loss: 0.0546, train F loss: 0.0422, acc 0.9832
epoch  21: train D loss: 0.0522, train F loss: 0.0407, acc 0.9856
epoch  22: train D loss: 0.0541, train F loss: 0.0248, acc 0.9884
epoch  23: train D loss: 0.0537, train F loss: 0.0352, acc 0.9872
epoch  24: train D loss: 0.0517, train F loss: 0.0291, acc 0.9884
epoch  25: train D loss: 0.0611, train F loss: 0.0304, acc 0.9866
epoch  26: train D loss: 0.0590, train F loss: 0.0407, acc 0.9840
epoch  27: train D loss: 0.0588, train F loss: 0.0312, acc 0.9886
epoch  28: train D loss: 0.0569, train F loss: 0.0347, acc 0.9852
epoch  29: train D loss: 0.0586, train F loss: 0.0501, acc 0.9810
epoch  30: train D loss: 0.0563, train F loss: 0.0530, acc 0.9796
epoch  31: train D loss: 0.0699, train F loss: 0.0683, acc 0.9734
epoch  32: train D loss: 0.0577, train F loss: 0.0367, acc 0.9862
epoch  33: train D loss: 0.0546, train F loss: 0.0385, acc 0.9860
epoch  34: train D loss: 0.0669, train F loss: 0.0304, acc 0.9868
epoch  35: train D loss: 0.0629, train F loss: 0.0350, acc 0.9846
epoch  36: train D loss: 0.0573, train F loss: 0.0194, acc 0.9918
epoch  37: train D loss: 0.0660, train F loss: 0.0222, acc 0.9886
epoch  38: train D loss: 0.0702, train F loss: 0.0388, acc 0.9852
epoch  39: train D loss: 0.0710, train F loss: 0.0333, acc 0.9868
epoch  40: train D loss: 0.0724, train F loss: 0.0372, acc 0.9828
epoch  41: train D loss: 0.0731, train F loss: 0.0312, acc 0.9856
epoch  42: train D loss: 0.0744, train F loss: 0.0263, acc 0.9890
epoch  43: train D loss: 0.0788, train F loss: 0.0238, acc 0.9876
epoch  44: train D loss: 0.0806, train F loss: 0.0312, acc 0.9862
epoch  45: train D loss: 0.0726, train F loss: 0.0442, acc 0.9808
epoch  46: train D loss: 0.0763, train F loss: 0.0461, acc 0.9814
epoch  47: train D loss: 0.0765, train F loss: 0.0501, acc 0.9818
epoch  48: train D loss: 0.0770, train F loss: 0.0327, acc 0.9884
epoch  49: train D loss: 0.0789, train F loss: 0.0294, acc 0.9874
epoch  50: train D loss: 0.0841, train F loss: 0.0306, acc 0.9860
epoch  51: train D loss: 0.0807, train F loss: 0.0439, acc 0.9810
epoch  52: train D loss: 0.0742, train F loss: 0.0327, acc 0.9872
epoch  53: train D loss: 0.0797, train F loss: 0.0293, acc 0.9870
epoch  54: train D loss: 0.0826, train F loss: 0.0342, acc 0.9848
epoch  55: train D loss: 0.0840, train F loss: 0.0353, acc 0.9846
epoch  56: train D loss: 0.0810, train F loss: 0.0187, acc 0.9898
epoch  57: train D loss: 0.0846, train F loss: 0.0278, acc 0.9878
epoch  58: train D loss: 0.0878, train F loss: 0.0430, acc 0.9820
epoch  59: train D loss: 0.0933, train F loss: 0.0413, acc 0.9828
epoch  60: train D loss: 0.0856, train F loss: 0.0380, acc 0.9864
epoch  61: train D loss: 0.0883, train F loss: 0.0312, acc 0.9856
epoch  62: train D loss: 0.0851, train F loss: 0.0281, acc 0.9888
epoch  63: train D loss: 0.0929, train F loss: 0.0244, acc 0.9886
epoch  64: train D loss: 0.0968, train F loss: 0.0327, acc 0.9848
epoch  65: train D loss: 0.0973, train F loss: 0.0300, acc 0.9866
epoch  66: train D loss: 0.1008, train F loss: 0.0298, acc 0.9860
epoch  67: train D loss: 0.0987, train F loss: 0.0480, acc 0.9790
epoch  68: train D loss: 0.1049, train F loss: 0.0304, acc 0.9856
epoch  69: train D loss: 0.1018, train F loss: 0.0231, acc 0.9870
epoch  70: train D loss: 0.0993, train F loss: 0.0237, acc 0.9874
epoch  71: train D loss: 0.1073, train F loss: 0.0213, acc 0.9896
epoch  72: train D loss: 0.1006, train F loss: 0.0291, acc 0.9874
epoch  73: train D loss: 0.1113, train F loss: 0.0322, acc 0.9864
epoch  74: train D loss: 0.1169, train F loss: 0.0280, acc 0.9864
epoch  75: train D loss: 0.0981, train F loss: 0.0250, acc 0.9866
epoch  76: train D loss: 0.1152, train F loss: 0.0200, acc 0.9894
epoch  77: train D loss: 0.1056, train F loss: 0.0209, acc 0.9884
epoch  78: train D loss: 0.1171, train F loss: 0.0323, acc 0.9834
epoch  79: train D loss: 0.1179, train F loss: 0.0358, acc 0.9834
epoch  80: train D loss: 0.1054, train F loss: 0.0220, acc 0.9884
epoch  81: train D loss: 0.1150, train F loss: 0.0454, acc 0.9808
epoch  82: train D loss: 0.1175, train F loss: 0.0211, acc 0.9900
epoch  83: train D loss: 0.1161, train F loss: 0.0178, acc 0.9898
epoch  84: train D loss: 0.1174, train F loss: 0.0285, acc 0.9870
epoch  85: train D loss: 0.1233, train F loss: 0.0360, acc 0.9836
epoch  86: train D loss: 0.1247, train F loss: 0.0277, acc 0.9870
epoch  87: train D loss: 0.1178, train F loss: 0.0126, acc 0.9914
epoch  88: train D loss: 0.1292, train F loss: 0.0260, acc 0.9860
epoch  89: train D loss: 0.1216, train F loss: 0.0266, acc 0.9858
epoch  90: train D loss: 0.1400, train F loss: 0.0245, acc 0.9872
epoch  91: train D loss: 0.1286, train F loss: 0.0178, acc 0.9876
epoch  92: train D loss: 0.1263, train F loss: 0.0142, acc 0.9914
epoch  93: train D loss: 0.1287, train F loss: 0.0249, acc 0.9874
epoch  94: train D loss: 0.1305, train F loss: 0.0230, acc 0.9868
epoch  95: train D loss: 0.1218, train F loss: 0.0244, acc 0.9882
epoch  96: train D loss: 0.1289, train F loss: 0.0261, acc 0.9872
epoch  97: train D loss: 0.1279, train F loss: 0.0220, acc 0.9878
epoch  98: train D loss: 0.1296, train F loss: 0.0240, acc 0.9880
epoch  99: train D loss: 0.1254, train F loss: 0.0158, acc 0.9906
epoch 100: train D loss: 0.1340, train F loss: 0.0096, acc 0.9928
epoch 101: train D loss: 0.1321, train F loss: 0.0208, acc 0.9876
epoch 102: train D loss: 0.1388, train F loss: 0.0338, acc 0.9824
epoch 103: train D loss: 0.1355, train F loss: 0.0224, acc 0.9874
epoch 104: train D loss: 0.1366, train F loss: 0.0405, acc 0.9806
epoch 105: train D loss: 0.1386, train F loss: 0.0367, acc 0.9838
epoch 106: train D loss: 0.1402, train F loss: 0.0294, acc 0.9872
epoch 107: train D loss: 0.1353, train F loss: 0.0310, acc 0.9850
epoch 108: train D loss: 0.1380, train F loss: 0.0107, acc 0.9918
epoch 109: train D loss: 0.1475, train F loss: 0.0178, acc 0.9892
epoch 110: train D loss: 0.1376, train F loss: 0.0189, acc 0.9892
epoch 111: train D loss: 0.1350, train F loss: 0.0119, acc 0.9908
epoch 112: train D loss: 0.1454, train F loss: 0.0132, acc 0.9902
epoch 113: train D loss: 0.1463, train F loss: 0.0373, acc 0.9818
epoch 114: train D loss: 0.1418, train F loss: 0.0376, acc 0.9802
epoch 115: train D loss: 0.1501, train F loss: 0.0323, acc 0.9834
epoch 116: train D loss: 0.1446, train F loss: 0.0132, acc 0.9902
epoch 117: train D loss: 0.1367, train F loss: 0.0181, acc 0.9896
epoch 118: train D loss: 0.1407, train F loss: 0.0171, acc 0.9908
epoch 119: train D loss: 0.1416, train F loss: 0.0169, acc 0.9890
epoch 120: train D loss: 0.1469, train F loss: 0.0152, acc 0.9914
epoch 121: train D loss: 0.1444, train F loss: 0.0141, acc 0.9906
epoch 122: train D loss: 0.1522, train F loss: 0.0237, acc 0.9854
epoch 123: train D loss: 0.1450, train F loss: 0.0274, acc 0.9856
epoch 124: train D loss: 0.1530, train F loss: 0.0134, acc 0.9900
epoch 125: train D loss: 0.1607, train F loss: 0.0277, acc 0.9848
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">paddle.save(feature_extractor.state_dict(), <span class="string">&quot;model/feature_extractor_final.pdparams&quot;</span>)</span><br><span class="line">paddle.save(label_predictor.state_dict(), <span class="string">&quot;model/label_predictor_final.pdparams&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-5-4-可视化训练过程"><a href="#3-5-4-可视化训练过程" class="headerlink" title="3.5.4 可视化训练过程"></a>3.5.4 可视化训练过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#分开绘制三条曲线</span></span><br><span class="line">epochs = <span class="built_in">range</span>(epoch)</span><br><span class="line"><span class="comment"># 模型训练可视化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_process</span>(<span class="params">title,color,iters,data,label</span>):</span></span><br><span class="line">    plt.title(title, fontsize=<span class="number">20</span>)  <span class="comment"># 标题</span></span><br><span class="line">    plt.xlabel(<span class="string">&quot;epochs&quot;</span>, fontsize=<span class="number">15</span>)  <span class="comment"># x轴</span></span><br><span class="line">    plt.ylabel(label, fontsize=<span class="number">15</span>)  <span class="comment"># y轴</span></span><br><span class="line">    plt.plot(iters, data,color=color,label=label)   <span class="comment"># 画图</span></span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(title))</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># Domain Classifier train loss</span></span><br><span class="line">draw_process(<span class="string">&quot;train D loss&quot;</span>,<span class="string">&quot;green&quot;</span>,epochs,train_D_loss_history,<span class="string">&quot;loss&quot;</span>) </span><br><span class="line"><span class="comment"># Feature Extrator train loss</span></span><br><span class="line">draw_process(<span class="string">&quot;train F loss&quot;</span>,<span class="string">&quot;green&quot;</span>,epochs,train_F_loss_history,<span class="string">&quot;loss&quot;</span>) </span><br><span class="line"><span class="comment"># Label Predictor的train accuracy</span></span><br><span class="line">draw_process(<span class="string">&quot;train acc&quot;</span>,<span class="string">&quot;red&quot;</span>,epochs,train_acc_history,<span class="string">&quot;accuracy&quot;</span>) </span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210415145842614.jpg?ype_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415145854814.jpg?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415145906343.jpg?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="4-模型预测"><a href="#4-模型预测" class="headerlink" title="4 模型预测"></a>4 模型预测</h1><p>在测试集上执行预测</p>
<h2 id="4-1-预测测试集结果"><a href="#4-1-预测测试集结果" class="headerlink" title="4.1 预测测试集结果"></a>4.1 预测测试集结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">result = []</span><br><span class="line">label_predictor.<span class="built_in">eval</span>()</span><br><span class="line">feature_extractor.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">for</span> i, (test_data, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataloader):</span><br><span class="line">    test_data = test_data.cuda()</span><br><span class="line"></span><br><span class="line">    class_logits = label_predictor(feature_extractor(test_data))</span><br><span class="line"></span><br><span class="line">    x = paddle.argmax(class_logits, axis=<span class="number">1</span>).cpu().detach().numpy()</span><br><span class="line">    result.append(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">result = np.concatenate(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate your submission</span></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;id&#x27;</span>: np.arange(<span class="number">0</span>,<span class="built_in">len</span>(result)), <span class="string">&#x27;label&#x27;</span>: result&#125;)</span><br><span class="line">df.to_csv(<span class="string">&#x27;DaNN_submission.csv&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计预测的标签数量，10种图片的预测数量如下：</span></span><br><span class="line"><span class="built_in">print</span>(df.iloc[:,<span class="number">1</span>].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code>5    26514
3    20621
4    10328
7     9979
8     9213
1     9159
6     4518
9     4365
0     3781
2     1522
Name: label, dtype: int64
</code></pre>
<h2 id="4-2-展示预测结果"><a href="#4-2-展示预测结果" class="headerlink" title="4.2 展示预测结果"></a>4.2 展示预测结果</h2><p>展示前一百幅的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">labels = <span class="built_in">iter</span>(df[<span class="string">&#x27;label&#x27;</span>][<span class="number">0</span>:<span class="number">100</span>])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f_names</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">yield</span> <span class="string">&#x27;work/real_or_drawing/test_data/0/&#123;:05&#125;.bmp&#x27;</span>.<span class="built_in">format</span>(i)       </span><br><span class="line">names = <span class="built_in">iter</span>(f_names())</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        plt.subplot(<span class="number">1</span>, <span class="number">10</span>, i + <span class="number">1</span>)</span><br><span class="line">        name = <span class="built_in">next</span>(names)</span><br><span class="line">        label = <span class="built_in">next</span>(labels)</span><br><span class="line">        fig = no_axis_show(plt.imread(name),title=titles[label])</span><br><span class="line"><span class="keyword">yield</span> <span class="string">&#x27;work/real_or_drawing/test_data/0/&#123;:05&#125;.bmp&#x27;</span>.<span class="built_in">format</span>(i)        </span><br><span class="line">names = <span class="built_in">iter</span>(f_names())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        plt.subplot(<span class="number">1</span>, <span class="number">10</span>, i + <span class="number">1</span>)</span><br><span class="line">        name = <span class="built_in">next</span>(names)</span><br><span class="line">        label = <span class="built_in">next</span>(labels)</span><br><span class="line">        fig = no_axis_show(plt.imread(name),title=titles[label])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20210415150045964.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045975.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045971.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045967.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045956.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045956.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045968.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045959.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045951.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210415150045959.png" alt="在这里插入图片描述"></p>
<h1 id="5-总结分析"><a href="#5-总结分析" class="headerlink" title="5 总结分析"></a>5 总结分析</h1><p>本次项目共进行了三次训练：第一次训练200个epochs,第二次训练125个epoch，第三次250个epoch。<br>可以通过以下的曲线对比，模型的训练可视化如下，可以发现：</p>
<ul>
<li>1） 三次训练中特征抽取器(Feature Extractor)的train F loss曲线都呈现下降趋势。</li>
<li>2） 而epoch=125,和epoch=200时，领域的分类器(Domain Classifier)的train D loss曲线呈现增大的趋势，可能原因是训练不稳定；epoch=250,领域的分类器(Domain Classifier)的train D loss曲线逐渐收敛。</li>
<li>3）三次的训练，标签预测器(Label Lredictor)的acc曲线在上升，最终acc都在0.98左右。</li>
</ul>
<p>特征抽取器就是不断抽取一些领域分类器不一样的特征为了能骗过它。并且他们这样相生相克就是为了模型能有很好的预测能力，这在标签预测器的acc曲线充分地表现了出来。因此，这就是迁移学习——Domain-adversarial training的根本所在！（Domain-adversarial training可以看成GAN的一种。它想要把source data和target data转换到同样的领域上，让它们有同样的分布。）</p>
<blockquote>
<ul>
<li>epoch=125<br>训练过程不稳定</li>
</ul>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/428bdfb77336911ac1f5df797d4e4e22.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/4a378a5f4dbe078ec6161382c5d6841c.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/24f7bf78e34fd7b13b401e3db9be523e.png"></p>
<blockquote>
<ul>
<li>epoch=200</li>
</ul>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ec20633f7d6764a70a9ebb672cb9fca1.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/1293fe5e2ec18495617bef612711df9d.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/abbc156df82dbd3d44fdf5f2befd49f1.png"></p>
<blockquote>
<ul>
<li>epoch=250</li>
</ul>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20210416095102961.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210416095113511.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210416095123218.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>模型的前100张测试集结果对比：<br>就前100张预测图片来看，三种预测结果差别还挺大的，因为没有标签，无法得知预测结果好坏。</p>
<blockquote>
<p>epoch=125:</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2a96b01eda15d1f79ac63fec6d2faf9b.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/305bd558dfbbb20033ac809253990c80.png"></p>
<blockquote>
<p>epoch=200<br><img src="https://img-blog.csdnimg.cn/img_convert/f438de59acd27a79c2da6e6f1b0f5562.png"><br><img src="https://img-blog.csdnimg.cn/img_convert/942116228473e0d6b4e03edfc87431b8.png"><br>epoch=250</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20210416095346634.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2021041609540751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTI3MjE3Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="6-参考文献-amp-文章-amp-代码"><a href="#6-参考文献-amp-文章-amp-代码" class="headerlink" title="6 参考文献&amp;文章&amp;代码"></a>6 参考文献&amp;文章&amp;代码</h1><p>[1] <a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/education/group/info/1978">李宏毅机器学习</a><br>[2] <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44673043/article/details/114858094">https://blog.csdn.net/weixin_44673043/article/details/114858094</a><br>[3] <a target="_blank" rel="noopener" href="https://helloai.blog.csdn.net/article/details/104484924">https://helloai.blog.csdn.net/article/details/104484924</a><br>[4]<a target="_blank" rel="noopener" href="https://datawhalechina.github.io/leeml-notes/#/chapter30/chapter30">https://datawhalechina.github.io/leeml-notes/#/chapter30/chapter30</a></p>
<h1 id="作者介绍"><a href="#作者介绍" class="headerlink" title="作者介绍"></a>作者介绍</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/616597">百度AI Studio个人主页</a>, 我在AI Studio上获得白银等级，点亮2个徽章，来互关呀~<br>CSDN:<a target="_blank" rel="noopener" href="https://i.csdn.net/#/user-center/profile?spm=1011.2124.3001.5111">https://i.csdn.net/#/user-center/profile?spm=1011.2124.3001.5111</a><br>交流qq:3207820044</p>
</blockquote>

      
    </div>

    
    
    
     
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/30/json/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="healerson">
      <meta itemprop="description" content="choosing is more important">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the world of healerson">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/30/json/" class="post-title-link" itemprop="url">JSON 库开发</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-30 12:05:27" itemprop="dateCreated datePublished" datetime="2021-03-30T12:05:27+08:00">2021-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-04-22 20:15:30" itemprop="dateModified" datetime="2021-04-22T20:15:30+08:00">2021-04-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>参考《JSON 库教程》<br>#JSON 库教程（一）：启程*healerson</p>
<ul>
<li>2021/3/20</li>
</ul>
<p>本文是<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/json-tutorial">《JSON 库教程》</a>的第一个单元。教程练习源代码位于 <a target="_blank" rel="noopener" href="https://github.com/miloyip/json-tutorial">json-tutorial</a>。</p>
<p>本单元内容：</p>
<ol>
<li><a href="#1-json-%E6%98%AF%E4%BB%80%E4%B9%88">JSON 是什么</a></li>
<li><a href="#2-%E6%90%AD%E5%BB%BA%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83">搭建编译环境</a></li>
<li><a href="#3-%E5%A4%B4%E6%96%87%E4%BB%B6%E4%B8%8E-api-%E8%AE%BE%E8%AE%A1">头文件与 API 设计</a></li>
<li><a href="#4-json-%E8%AF%AD%E6%B3%95%E5%AD%90%E9%9B%86">JSON 语法子集</a></li>
<li><a href="#5-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95">单元测试</a></li>
<li><a href="#6-%E5%AE%8F%E7%9A%84%E7%BC%96%E5%86%99%E6%8A%80%E5%B7%A7">宏的编写技巧</a></li>
<li><a href="#7-%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90%E5%99%A8">实现解析器</a></li>
<li><a href="#8-%E5%85%B3%E4%BA%8E%E6%96%AD%E8%A8%80">关于断言</a></li>
<li><a href="#9-%E6%80%BB%E7%BB%93%E4%B8%8E%E7%BB%83%E4%B9%A0">总结与练习</a></li>
<li><a href="#10-%E5%B8%B8%E8%A7%81%E9%97%AE%E7%AD%94">常见问答</a></li>
</ol>
<h2 id="1-JSON-是什么"><a href="#1-JSON-是什么" class="headerlink" title="1. JSON 是什么"></a>1. JSON 是什么</h2><p>JSON（JavaScript Object Notation）是一个用于数据交换的文本格式，现时的标准为<a target="_blank" rel="noopener" href="https://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">ECMA-404</a>。</p>
<p>虽然 JSON 源至于 JavaScript 语言，但它只是一种数据格式，可用于任何编程语言。现时具类似功能的格式有 XML、YAML，当中以 JSON 的语法最为简单。</p>
<p>例如，一个动态网页想从服务器获得数据时，服务器从数据库查找数据，然后把数据转换成 JSON 文本格式：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;Design Patterns&quot;</span>,</span><br><span class="line">    <span class="string">&quot;subtitle&quot;</span>: <span class="string">&quot;Elements of Reusable Object-Oriented Software&quot;</span>,</span><br><span class="line">    <span class="string">&quot;author&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;Erich Gamma&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Richard Helm&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Ralph Johnson&quot;</span>,</span><br><span class="line">        <span class="string">&quot;John Vlissides&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;year&quot;</span>: <span class="number">2009</span>,</span><br><span class="line">    <span class="string">&quot;weight&quot;</span>: <span class="number">1.8</span>,</span><br><span class="line">    <span class="string">&quot;hardcover&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">&quot;publisher&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Company&quot;</span>: <span class="string">&quot;Pearson Education&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Country&quot;</span>: <span class="string">&quot;India&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;website&quot;</span>: <span class="literal">null</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>网页的脚本代码就可以把此 JSON 文本解析为内部的数据结构去使用。</p>
<p>从此例子可看出，JSON 是树状结构，而 JSON 只包含 6 种数据类型：</p>
<ul>
<li>null: 表示为 null</li>
<li>boolean: 表示为 true 或 false</li>
<li>number: 一般的浮点数表示方式，在下一单元详细说明</li>
<li>string: 表示为 “…”</li>
<li>array: 表示为 [ … ]</li>
<li>object: 表示为 { … }</li>
</ul>
<p>我们要实现的 JSON 库，主要是完成 3 个需求：</p>
<ol>
<li>把 JSON 文本解析为一个树状数据结构（parse）。</li>
<li>提供接口访问该数据结构（access）。</li>
<li>把数据结构转换成 JSON 文本（stringify）。</li>
</ol>
<p><img src="images/requirement.png" alt="requirement"></p>
<p>我们会逐步实现这些需求。在本单元中，我们只实现最简单的 null 和 boolean 解析。</p>
<h2 id="2-搭建编译环境"><a href="#2-搭建编译环境" class="headerlink" title="2. 搭建编译环境"></a>2. 搭建编译环境</h2><p>我们要做的库是跨平台、跨编译器的，同学可使用任意平台进行练习。</p>
<p>练习源代码位于 <a target="_blank" rel="noopener" href="https://github.com/miloyip/json-tutorial">json-tutorial</a>，当中 tutorial01 为本单元的练习代码。建议同学登记为 GitHub 用户，把项目 fork 一个自己的版本，然后在上面进行修改。不了解版本管理的同学，也可以按右方「Clone or download」按钮，简单下载一个 zip 文件。</p>
<p>我们的 JSON 库名为 leptjson，代码文件只有 3 个：</p>
<ol>
<li><code>leptjson.h</code>：leptjson 的头文件（header file），含有对外的类型和 API 函数声明。</li>
<li><code>leptjson.c</code>：leptjson 的实现文件（implementation file），含有内部的类型声明和函数实现。此文件会编译成库。</li>
<li><code>test.c</code>：我们使用测试驱动开发（test driven development, TDD）。此文件包含测试程序，需要链接 leptjson 库。</li>
</ol>
<p>为了方便跨平台开发，我们会使用一个现时最流行的软件配置工具 <a target="_blank" rel="noopener" href="https://cmake.org/">CMake</a>。</p>
<p>在 Windows 下，下载安装 CMake 后，可以使用其 cmake-gui 程序：</p>
<p><img src="images/cmake-gui.png" alt="cmake-gui"></p>
<p>先在 “Where is the source code” 选择 json-tutorial/tutorial01，再在 “Where to build the binary” 键入上一个目录加上 /build。</p>
<p>按 Configure，选择编译器，然后按 Generate 便会生成 Visual Studio 的 .sln 和 .vcproj 等文件。注意这个 build 目录都是生成的文件，可以随时删除，也不用上传至仓库。</p>
<p>在 OS X 下，建议安装 <a target="_blank" rel="noopener" href="https://brew.sh/">Homebrew</a>，然后在命令行键入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ brew install cmake</span><br><span class="line">$ cd github&#x2F;json-tutorial&#x2F;tutorial01</span><br><span class="line">$ mkdir build</span><br><span class="line">$ cd build</span><br><span class="line">$ cmake -DCMAKE_BUILD_TYPE&#x3D;Debug ..</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure>

<p>这样会使用 GNU make 来生成项目，把 Debug 改成 Release 就会生成 Release 配置的 makefile。</p>
<p>若你喜欢的话，CMake 也可以生成 Xcode 项目：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cmake -G Xcode ..</span><br><span class="line">$ open leptjson_test.xcodeproj</span><br></pre></td></tr></table></figure>

<p>而在 Ubuntu 下，可使用 <code>apt-get</code> 来安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install cmake</span><br></pre></td></tr></table></figure>

<p>无论使用什么平台及编译环境，编译运行后会出现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;leptjson_test</span><br><span class="line">&#x2F;Users&#x2F;miloyip&#x2F;github&#x2F;json-tutorial&#x2F;tutorial01&#x2F;test.c:56: expect: 3 actual: 0</span><br><span class="line">11&#x2F;12 (91.67%) passed</span><br></pre></td></tr></table></figure>

<p>若看到类似以上的结果，说明已成功搭建编译环境，我们可以去看看那几个代码文件的内容了。</p>
<h2 id="3-头文件与-API-设计"><a href="#3-头文件与-API-设计" class="headerlink" title="3. 头文件与 API 设计"></a>3. 头文件与 API 设计</h2><p>C 语言有头文件的概念，需要使用 <code>#include</code>去引入头文件中的类型声明和函数声明。但由于头文件也可以 <code>#include</code> 其他头文件，为避免重复声明，通常会利用宏加入 include 防范（include guard）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> LEPTJSON_H__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LEPTJSON_H__</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* LEPTJSON_H__ */</span></span></span><br></pre></td></tr></table></figure>

<p>宏的名字必须是唯一的，通常习惯以 <code>_H__</code> 作为后缀。由于 leptjson 只有一个头文件，可以简单命名为 <code>LEPTJSON_H__</code>。如果项目有多个文件或目录结构，可以用 <code>项目名称_目录_文件名称_H__</code> 这种命名方式。</p>
<p>如前所述，JSON 中有 6 种数据类型，如果把 true 和 false 当作两个类型就是 7 种，我们为此声明一个枚举类型（enumeration type）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">enum</span> &#123;</span> LEPT_NULL, LEPT_FALSE, LEPT_TRUE, LEPT_NUMBER, LEPT_STRING, LEPT_ARRAY, LEPT_OBJECT &#125; lept_type;</span><br></pre></td></tr></table></figure>

<p>因为 C 语言没有 C++ 的命名空间（namespace）功能，一般会使用项目的简写作为标识符的前缀。通常枚举值用全大写（如 <code>LEPT_NULL</code>），而类型及函数则用小写（如 <code>lept_type</code>）。</p>
<p>接下来，我们声明 JSON 的数据结构。JSON 是一个树形结构，我们最终需要实现一个树的数据结构，每个节点使用 <code>lept_value</code> 结构体表示，我们会称它为一个 JSON 值（JSON value）。<br>在此单元中，我们只需要实现 null, true 和 false 的解析，因此该结构体只需要存储一个 lept_type。之后的单元会逐步加入其他数据。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    lept_type type;</span><br><span class="line">&#125;lept_value;</span><br></pre></td></tr></table></figure>

<p>C 语言的结构体是以 <code>struct X &#123;&#125;</code> 形式声明的，定义变量时也要写成 <code>struct X x;</code>。为方便使用，上面的代码使用了 <code>typedef</code>。</p>
<p>然后，我们现在只需要两个 API 函数，一个是解析 JSON：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lept_parse</span><span class="params">(lept_value* v, <span class="keyword">const</span> <span class="keyword">char</span>* json)</span></span>;</span><br></pre></td></tr></table></figure>

<p>传入的 JSON 文本是一个 C 字符串（空结尾字符串／null-terminated string），由于我们不应该改动这个输入字符串，所以使用 <code>const char*</code> 类型。</p>
<p>另一注意点是，传入的根节点指针 v 是由使用方负责分配的，所以一般用法是：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lept_value v;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span> json[] = ...;</span><br><span class="line"><span class="keyword">int</span> ret = lept_parse(&amp;v, json);</span><br></pre></td></tr></table></figure>

<p>返回值是以下这些枚举值，无错误会返回 <code>LEPT_PARSE_OK</code>，其他值在下节解释。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> &#123;</span></span><br><span class="line">    LEPT_PARSE_OK = <span class="number">0</span>,</span><br><span class="line">    LEPT_PARSE_EXPECT_VALUE,</span><br><span class="line">    LEPT_PARSE_INVALID_VALUE,</span><br><span class="line">    LEPT_PARSE_ROOT_NOT_SINGULAR</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>现时我们只需要一个访问结果的函数，就是获取其类型：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">lept_type <span class="title">lept_get_type</span><span class="params">(<span class="keyword">const</span> lept_value* v)</span></span>;</span><br></pre></td></tr></table></figure>

<h2 id="4-JSON-语法子集"><a href="#4-JSON-语法子集" class="headerlink" title="4. JSON 语法子集"></a>4. JSON 语法子集</h2><p>下面是此单元的 JSON 语法子集，使用 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7159">RFC7159</a> 中的 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc5234">ABNF</a> 表示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JSON-text &#x3D; ws value ws</span><br><span class="line">ws &#x3D; *(%x20 &#x2F; %x09 &#x2F; %x0A &#x2F; %x0D)</span><br><span class="line">value &#x3D; null &#x2F; false &#x2F; true </span><br><span class="line">null  &#x3D; &quot;null&quot;</span><br><span class="line">false &#x3D; &quot;false&quot;</span><br><span class="line">true  &#x3D; &quot;true&quot;</span><br></pre></td></tr></table></figure>

<p>当中 <code>%xhh</code> 表示以 16 进制表示的字符，<code>/</code> 是多选一，<code>*</code> 是零或多个，<code>()</code> 用于分组。</p>
<p>那么第一行的意思是，JSON 文本由 3 部分组成，首先是空白（whitespace），接着是一个值，最后是空白。</p>
<p>第二行告诉我们，所谓空白，是由零或多个空格符（space U+0020）、制表符（tab U+0009）、换行符（LF U+000A）、回车符（CR U+000D）所组成。</p>
<p>第三行是说，我们现时的值只可以是 null、false 或 true，它们分别有对应的字面值（literal）。</p>
<p>我们的解析器应能判断输入是否一个合法的 JSON。如果输入的 JSON 不合符这个语法，我们要产生对应的错误码，方便使用者追查问题。</p>
<p>在这个 JSON 语法子集下，我们定义 3 种错误码：</p>
<ul>
<li>若一个 JSON 只含有空白，传回 <code>LEPT_PARSE_EXPECT_VALUE</code>。</li>
<li>若一个值之后，在空白之后还有其他字符，传回 <code>LEPT_PARSE_ROOT_NOT_SINGULAR</code>。</li>
<li>若值不是那三种字面值，传回 <code>LEPT_PARSE_INVALID_VALUE</code>。</li>
</ul>
<h2 id="5-单元测试"><a href="#5-单元测试" class="headerlink" title="5. 单元测试"></a>5. 单元测试</h2><p>许多同学在做练习题时，都是以 <code>printf</code>／<code>cout</code> 打印结果，再用肉眼对比结果是否乎合预期。但当软件项目越来越复杂，这个做法会越来越低效。一般我们会采用自动的测试方式，例如单元测试（unit testing）。单元测试也能确保其他人修改代码后，原来的功能维持正确（这称为回归测试／regression testing）。</p>
<p>常用的单元测试框架有 xUnit 系列，如 C++ 的 <a target="_blank" rel="noopener" href="https://github.com/google/googletest">Google Test</a>、C# 的 <a target="_blank" rel="noopener" href="https://www.nunit.org/">NUnit</a>。我们为了简单起见，会编写一个极简单的单元测试方式。</p>
<p>一般来说，软件开发是以周期进行的。例如，加入一个功能，再写关于该功能的单元测试。但也有另一种软件开发方法论，称为测试驱动开发（test-driven development, TDD），它的主要循环步骤是：</p>
<ol>
<li>加入一个测试。</li>
<li>运行所有测试，新的测试应该会失败。</li>
<li>编写实现代码。</li>
<li>运行所有测试，若有测试失败回到3。</li>
<li>重构代码。</li>
<li>回到 1。</li>
</ol>
<p>TDD 是先写测试，再实现功能。好处是实现只会刚好满足测试，而不会写了一些不需要的代码，或是没有被测试的代码。</p>
<p>但无论我们是采用 TDD，或是先实现后测试，都应尽量加入足够覆盖率的单元测试。</p>
<p>回到 leptjson 项目，<code>test.c</code> 包含了一个极简的单元测试框架：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;leptjson.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> main_ret = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> test_count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> test_pass = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> EXPECT_EQ_BASE(equality, expect, actual, format) \</span></span><br><span class="line">    <span class="keyword">do</span> &#123;\</span><br><span class="line">        test_count++;\</span><br><span class="line">        <span class="keyword">if</span> (equality)\</span><br><span class="line">            test_pass++;\</span><br><span class="line">        <span class="keyword">else</span> &#123;\</span><br><span class="line">            <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;%s:%d: expect: &quot;</span> format <span class="string">&quot; actual: &quot;</span> format <span class="string">&quot;\n&quot;</span>, __FILE__, __LINE__, expect, actual);\</span><br><span class="line">            main_ret = <span class="number">1</span>;\</span><br><span class="line">        &#125;\</span><br><span class="line">    &#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> EXPECT_EQ_INT(expect, actual) EXPECT_EQ_BASE((expect) == (actual), expect, actual, <span class="meta-string">&quot;%d&quot;</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_parse_null</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    lept_value v;</span><br><span class="line">    v.type = LEPT_TRUE;</span><br><span class="line">    EXPECT_EQ_INT(LEPT_PARSE_OK, lept_parse(&amp;v, <span class="string">&quot;null&quot;</span>));</span><br><span class="line">    EXPECT_EQ_INT(LEPT_NULL, lept_get_type(&amp;v));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_parse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    test_parse_null();</span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    test_parse();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d/%d (%3.2f%%) passed\n&quot;</span>, test_pass, test_count, test_pass * <span class="number">100.0</span> / test_count);</span><br><span class="line">    <span class="keyword">return</span> main_ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>现时只提供了一个 <code>EXPECT_EQ_INT(expect, actual)</code> 的宏，每次使用这个宏时，如果 expect != actual（预期值不等于实际值），便会输出错误信息。<br>若按照 TDD 的步骤，我们先写一个测试，如上面的 <code>test_parse_null()</code>，而 <code>lept_parse()</code> 只返回 <code>LEPT_PARSE_OK</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;Users&#x2F;miloyip&#x2F;github&#x2F;json-tutorial&#x2F;tutorial01&#x2F;test.c:27: expect: 0 actual: 1</span><br><span class="line">1&#x2F;2 (50.00%) passed</span><br></pre></td></tr></table></figure>

<p>第一个返回 <code>LEPT_PARSE_OK</code>，所以是通过的。第二个测试因为 <code>lept_parse()</code> 没有把 <code>v.type</code> 改成 <code>LEPT_NULL</code>，造成失败。我们再实现 <code>lept_parse()</code> 令到它能通过测试。</p>
<p>然而，完全按照 TDD 的步骤来开发，是会减慢开发进程。所以我个人会在这两种极端的工作方式取平衡。通常会在设计 API 后，先写部分测试代码，再写满足那些测试的实现。</p>
<h2 id="6-宏的编写技巧"><a href="#6-宏的编写技巧" class="headerlink" title="6. 宏的编写技巧"></a>6. 宏的编写技巧</h2><p>有些同学可能不了解 <code>EXPECT_EQ_BASE</code> 宏的编写技巧，简单说明一下。反斜线代表该行未结束，会串接下一行。而如果宏里有多过一个语句（statement），就需要用 <code>do &#123; /*...*/ &#125; while(0)</code> 包裹成单个语句，否则会有如下的问题：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> M() a(); b()</span></span><br><span class="line"><span class="keyword">if</span> (cond)</span><br><span class="line">    M();</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    c();</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 预处理后 */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cond)</span><br><span class="line">    a(); b(); <span class="comment">/* b(); 在 if 之外     */</span></span><br><span class="line"><span class="keyword">else</span>          <span class="comment">/* &lt;- else 缺乏对应 if */</span></span><br><span class="line">    c();</span><br></pre></td></tr></table></figure>

<p>只用 <code>&#123; &#125;</code> 也不行：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> M() &#123; a(); b(); &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 预处理后 */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cond)</span><br><span class="line">    &#123; a(); b(); &#125;; <span class="comment">/* 最后的分号代表 if 语句结束 */</span></span><br><span class="line"><span class="keyword">else</span>               <span class="comment">/* else 缺乏对应 if */</span></span><br><span class="line">    c();</span><br></pre></td></tr></table></figure>

<p>用 do while 就行了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> M() do &#123; a(); b(); &#125; while(0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 预处理后 */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cond)</span><br><span class="line">    <span class="keyword">do</span> &#123; a(); b(); &#125; <span class="keyword">while</span>(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    c();</span><br></pre></td></tr></table></figure>

<h2 id="7-实现解析器"><a href="#7-实现解析器" class="headerlink" title="7. 实现解析器"></a>7. 实现解析器</h2><p>有了 API 的设计、单元测试，终于要实现解析器了。</p>
<p>首先为了减少解析函数之间传递多个参数，我们把这些数据都放进一个 <code>lept_context</code> 结构体：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* json;</span><br><span class="line">&#125;lept_context;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 提示：这里应该是 JSON-text = ws value ws */</span></span><br><span class="line"><span class="comment">/* 以下实现没处理最后的 ws 和 LEPT_PARSE_ROOT_NOT_SINGULAR */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lept_parse</span><span class="params">(lept_value* v, <span class="keyword">const</span> <span class="keyword">char</span>* json)</span> </span>&#123;</span><br><span class="line">    lept_context c;</span><br><span class="line">    assert(v != <span class="literal">NULL</span>);</span><br><span class="line">    c.json = json;</span><br><span class="line">    v-&gt;type = LEPT_NULL;</span><br><span class="line">    lept_parse_whitespace(&amp;c);</span><br><span class="line">    <span class="keyword">return</span> lept_parse_value(&amp;c, v);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>暂时我们只储存 json 字符串当前位置，之后的单元我们需要加入更多内容。</p>
<p>若 <code>lept_parse()</code> 失败，会把 <code>v</code> 设为 <code>null</code> 类型，所以这里先把它设为 <code>null</code>，让 <code>lept_parse_value()</code> 写入解析出来的根值。</p>
<p>leptjson 是一个手写的递归下降解析器（recursive descent parser）。由于 JSON 语法特别简单，我们不需要写分词器（tokenizer），只需检测下一个字符，便可以知道它是哪种类型的值，然后调用相关的分析函数。对于完整的 JSON 语法，跳过空白后，只需检测当前字符：</p>
<ul>
<li>n ➔ null</li>
<li>t ➔ true</li>
<li>f ➔ false</li>
<li>“ ➔ string</li>
<li>0-9/- ➔ number</li>
<li>[ ➔ array</li>
<li>{ ➔ object</li>
</ul>
<p>所以，我们可以按照 JSON 语法一节的 EBNF 简单翻译成解析函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> EXPECT(c, ch) do &#123; assert(*c-&gt;json == (ch)); c-&gt;json++; &#125; while(0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* ws = *(%x20 / %x09 / %x0A / %x0D) */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lept_parse_whitespace</span><span class="params">(lept_context* c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span> *p = c-&gt;json;</span><br><span class="line">    <span class="keyword">while</span> (*p == <span class="string">&#x27; &#x27;</span> || *p == <span class="string">&#x27;\t&#x27;</span> || *p == <span class="string">&#x27;\n&#x27;</span> || *p == <span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">        p++;</span><br><span class="line">    c-&gt;json = p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* null  = &quot;null&quot; */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">lept_parse_null</span><span class="params">(lept_context* c, lept_value* v)</span> </span>&#123;</span><br><span class="line">    EXPECT(c, <span class="string">&#x27;n&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (c-&gt;json[<span class="number">0</span>] != <span class="string">&#x27;u&#x27;</span> || c-&gt;json[<span class="number">1</span>] != <span class="string">&#x27;l&#x27;</span> || c-&gt;json[<span class="number">2</span>] != <span class="string">&#x27;l&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> LEPT_PARSE_INVALID_VALUE;</span><br><span class="line">    c-&gt;json += <span class="number">3</span>;</span><br><span class="line">    v-&gt;type = LEPT_NULL;</span><br><span class="line">    <span class="keyword">return</span> LEPT_PARSE_OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* value = null / false / true */</span></span><br><span class="line"><span class="comment">/* 提示：下面代码没处理 false / true，将会是练习之一 */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">lept_parse_value</span><span class="params">(lept_context* c, lept_value* v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (*c-&gt;json) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;n&#x27;</span>:  <span class="keyword">return</span> lept_parse_null(c, v);</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;\0&#x27;</span>: <span class="keyword">return</span> LEPT_PARSE_EXPECT_VALUE;</span><br><span class="line">        <span class="keyword">default</span>:   <span class="keyword">return</span> LEPT_PARSE_INVALID_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于 <code>lept_parse_whitespace()</code> 是不会出现错误的，返回类型为 <code>void</code>。其它的解析函数会返回错误码，传递至顶层。</p>
<h2 id="8-关于断言"><a href="#8-关于断言" class="headerlink" title="8. 关于断言"></a>8. 关于断言</h2><p>断言（assertion）是 C 语言中常用的防御式编程方式，减少编程错误。最常用的是在函数开始的地方，检测所有参数。有时候也可以在调用函数后，检查上下文是否正确。</p>
<p>C 语言的标准库含有 <a target="_blank" rel="noopener" href="https://en.cppreference.com/w/c/error/assert"><code>assert()</code></a> 这个宏（需 <code>#include &lt;assert.h&gt;</code>），提供断言功能。当程序以 release 配置编译时（定义了 <code>NDEBUG</code> 宏），<code>assert()</code> 不会做检测；而当在 debug 配置时（没定义 <code>NDEBUG</code> 宏），则会在运行时检测 <code>assert(cond)</code> 中的条件是否为真（非 0），断言失败会直接令程序崩溃。</p>
<p>例如上面的 <code>lept_parse_null()</code> 开始时，当前字符应该是 <code>&#39;n&#39;</code>，所以我们使用一个宏 <code>EXPECT(c, ch)</code> 进行断言，并跳到下一字符。</p>
<p>初使用断言的同学，可能会错误地把含<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Side_effect_(computer_science)">副作用</a>的代码放在 <code>assert()</code> 中：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assert(x++ == <span class="number">0</span>); <span class="comment">/* 这是错误的! */</span></span><br></pre></td></tr></table></figure>

<p>这样会导致 debug 和 release 版的行为不一样。</p>
<p>另一个问题是，初学者可能会难于分辨何时使用断言，何时处理运行时错误（如返回错误值或在 C++ 中抛出异常）。简单的答案是，如果那个错误是由于程序员错误编码所造成的（例如传入不合法的参数），那么应用断言；如果那个错误是程序员无法避免，而是由运行时的环境所造成的，就要处理运行时错误（例如开启文件失败）。</p>
<h2 id="9-总结与练习"><a href="#9-总结与练习" class="headerlink" title="9. 总结与练习"></a>9. 总结与练习</h2><p>本文介绍了如何配置一个编程环境，单元测试的重要性，以至于一个 JSON 解析器的子集实现。如果你读到这里，还未动手，建议你快点试一下。以下是本单元的练习，很容易的，但我也会在稍后发出解答篇。</p>
<ol>
<li>修正关于 <code>LEPT_PARSE_ROOT_NOT_SINGULAR</code> 的单元测试，若 json 在一个值之后，空白之后还有其它字符，则要返回 <code>LEPT_PARSE_ROOT_NOT_SINGULAR</code>。</li>
<li>参考 <code>test_parse_null()</code>，加入 <code>test_parse_true()</code>、<code>test_parse_false()</code> 单元测试。</li>
<li>参考 <code>lept_parse_null()</code> 的实现和调用方，解析 true 和 false 值。</li>
</ol>
<h2 id="10-常见问答"><a href="#10-常见问答" class="headerlink" title="10. 常见问答"></a>10. 常见问答</h2><ol>
<li><p>为什么把例子命名为 leptjson？</p>
<p>来自于标准模型中的轻子（lepton），意为很轻量的 JSON 库。另外，建议大家为项目命名时，先 google 一下是否够独特，有很多同名的话搜寻时难以命中。</p>
</li>
<li><p>为什么使用宏而不用函数或内联函数？</p>
<p>因为这个测试框架使用了 <code>__LINE__</code> 这个编译器提供的宏，代表编译时该行的行号。如果用函数或内联函数，每次的行号便都会相同。另外，内联函数是 C99 的新增功能，本教程使用 C89。</p>
</li>
</ol>
<p>其他常见问答将会从评论中整理。</p>

      
    </div>

    
    
    
     
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/25/linux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="healerson">
      <meta itemprop="description" content="choosing is more important">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="the world of healerson">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/25/linux/" class="post-title-link" itemprop="url">局域网内常见服务器的搭建(一)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-25 21:50:21" itemprop="dateCreated datePublished" datetime="2021-03-25T21:50:21+08:00">2021-03-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-04-22 20:50:39" itemprop="dateModified" datetime="2021-04-22T20:50:39+08:00">2021-04-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>参考鸟哥的的Linux私房菜，unix网络编程，unix环境高级编程</p>
<h2 id="远程连接服务器"><a href="#远程连接服务器" class="headerlink" title="远程连接服务器"></a>远程连接服务器</h2><h3 id="SSH服务器"><a href="#SSH服务器" class="headerlink" title="SSH服务器"></a>SSH服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">文字接口连接服务器</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="http://linux.vbird.org/book/">SSH</a></p>
<h3 id="XDMCP服务器"><a href="#XDMCP服务器" class="headerlink" title="XDMCP服务器"></a>XDMCP服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最原始的图形接口</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="http://linux.vbird.org/book/">XDMCP</a></p>
<h3 id="VNC服务器"><a href="#VNC服务器" class="headerlink" title="VNC服务器"></a>VNC服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">华丽的图形接口</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="http://linux.vbird.org/book/">VNC</a></p>
<h3 id="XRDP服务器"><a href="#XRDP服务器" class="headerlink" title="XRDP服务器"></a>XRDP服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">仿真的远程桌面系统</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="http://linux.vbird.org/book/">XRDP</a></p>

      
    </div>

    
    
    
     
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="healerson"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">healerson</p>
  <div class="site-description" itemprop="description">choosing is more important</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/healerson" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;healerson" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/1551908886@qq.com" title="E-Mail → 1551908886@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/" title="Twitter → https:&#x2F;&#x2F;twitter.com" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://youtube.com/" title="YouTube → https:&#x2F;&#x2F;youtube.com" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/" title="Instagram → https:&#x2F;&#x2F;instagram.com" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://https//blog.csdn.net/Later_001" title="CSDN → https:&#x2F;&#x2F;https:&#x2F;&#x2F;blog.csdn.net&#x2F;Later_001" rel="noopener" target="_blank"><i class="fab fa-codiepie fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/mai-nv-hai-de-xiao-huo-chai-35-19" title="zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mai-nv-hai-de-xiao-huo-chai-35-19" rel="noopener" target="_blank"><i class="fab fa-gratipay fa-fw"></i>zhihu</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://baidu.com/" title="https:&#x2F;&#x2F;baidu.com" rel="noopener" target="_blank">百度</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://fishc.com.cn/" title="https:&#x2F;&#x2F;fishc.com.cn" rel="noopener" target="_blank">鱼c</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.csdn.net/" title="https:&#x2F;&#x2F;www.csdn.net" rel="noopener" target="_blank">CSDN</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-03 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">healerson</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共14k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  















  

  

</body>
</html>
